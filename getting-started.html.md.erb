---
title: Getting Started&#58; ODB on a Local Development Environment
owner: London Services Enablement
---

This guide describes how to create and manage an on-demand service using PCF Dev and BOSH lite, which are tools that allow you run BOSH and Pivotal Cloud Foundry on a local development machine. This tutorial bases its example service on [Kafka open source messaging](http://kafka.apache.org) and uses the following sample code directories:

* [Kafka example service](https://github.com/pivotal-cf-experimental/kafka-example-service-release)
* [Kafka example service adapter](https://github.com/pivotal-cf-experimental/kafka-example-service-adapter)
* [Kafka example app](https://github.com/pivotal-cf-experimental/kafka-example-app)

## <a id="prereq"></a>Prerequisites

Before setting up and using ODB on your local development environment, install and configure the following components:

- [BOSH Lite](https://github.com/cloudfoundry/bosh-lite#install-bosh-lite) - *min version <%= vars.odb_bosh_lite_version %>*

 <p class="note">**Note**: For PCF Dev to route requests to the deployments on BOSH Lite ensure you run the script `bin/add-route` in the BOSH Lite repository. You may need to run this again if your networking is reset (e.g. reboot, or connecting to a different network).</p>

- [PCF Dev](https://docs.pivotal.io/pcf-dev/#installing) - *[<%= vars.odb_pcfdev_version %>](https://network.pivotal.io/products/pcfdev#/releases/<%= vars.odb_pcfdev_version_pivnet %>)*

- Once PCF Dev has finished installing, you should see some output like this...

  ```sh
      _______  _______  _______    ______   _______  __   __
    |       ||       ||       |  |      | |       ||  | |  |
    |    _  ||       ||    ___|  |  _    ||    ___||  |_|  |
    |   |_| ||       ||   |___   | | |   ||   |___ |       |
    |    ___||      _||    ___|  | |_|   ||    ___||       |
    |   |    |     |_ |   |      |       ||   |___  |     |
    |___|    |_______||___|      |______| |_______|  |___|
    is now running.
    To begin using PCF Dev, please run:
       cf login -a https://api.local.pcfdev.io --skip-ssl-validation
    Apps Manager URL: https://local.pcfdev.io
    Admin user => Email: admin / Password: admin
  ```

  Make a note of the <CF_DOMAIN>, you will need this later on. It is usually `local.pcfdev.io`

## <a id="set_up_bosh"></a>Step 1: Set Up BOSH Lite

1. Target your BOSH Lite installation:
   <pre class="terminal">
    $ bosh target
    Current target is https<span>:</span>//192.168.50.4:25555 (Bosh Lite Director)
   </pre>

1. Upload the [BOSH Lite stemcell](http://bosh.cloudfoundry.org/stemcells/bosh-warden-boshlite-ubuntu-trusty-go_agent):
   <pre class="terminal">
    $ bosh upload stemcell https<span>:</span>//bosh.io/d/stemcells/bosh-warden-boshlite-ubuntu-trusty-go_agent?v=<%= vars.odb_warden_stemcell_version %>
   </pre>

## <a id="set_up_kafka_sr"></a> Step 2: Set Up the Kafka Example Service

1. Clone the [Kafka example service](https://github.com/pivotal-cf-experimental/kafka-example-service-release) into your workspace:
   <pre class="terminal">
    $ git clone https<span>:</span>//github.com/pivotal-cf-experimental/kafka-example-service-release.git
   </pre>

1. In the `kafka-example-service-release` directory, create and upload the kafka example service:
   <pre class="terminal">
    $ cd kafka-example-service-release
    $ bosh create release --name kafka-example-service
   </pre>

1. Upload the service to the BOSH director:
  <pre class="terminal">
    $ bosh upload release
  </pre>

## <a id="set_up_kafka_sa"></a> Step 3: Set Up the Kafka Example Service Adapter

1. Clone the [Kafka example service adapter](https://github.com/pivotal-cf-experimental/kafka-example-service-adapter-release) and run `git submodule update --init` to bring in the adapter's dependencies
   <pre class="terminal">
    $ git clone https<span>:</span>//github.com/pivotal-cf-experimental/kafka-example-service-adapter-release.git
   </pre>

1. Update the service adapter dependencies:
  <pre class="terminal">
    $ cd kafka-example-service-adapter-release
    $ git submodule update --init --recursive
  </pre>

1. Create the example service adapter:
  <pre class="terminal">
    $ bosh create release --name kafka-example-service-adapter
  </pre>

1. Upload the example service adapter to the BOSH director:
  <pre class="terminal">
    $ bosh upload release
  </pre>

## <a id="set_up_odb"></a> Step 4: Set Up the On-Demand Broker

1. Clone the [on-demand broker](https://github.com/pivotal-cf/on-demand-service-broker-release)
  <pre class="terminal">
    $ git clone https://github.com/pivotal-cf/on-demand-service-broker-release.git
  </pre>

1. Update submodule dependencies:
  <pre class="terminal">
    $ cd on-demand-service-broker-release
    $ git submodule update --init --recursive
  </pre>

1. Create the `on-demand-service-broker` release:
  <pre class="terminal">
    $ bosh create release --name on-demand-service-broker
  </pre>

1. Upload the `on-demand-service-broker` release:
  <pre class="terminal">
    $ bosh upload release
  </pre>

## <a id="create_bosh"></a> Step 5: Create a BOSH Deployment

1. Create a new directory in your workspace and a `cloud_config.yml` for the BOSH Lite Director. For example:

    ```yaml
    vm_types:
    - name: container
      cloud_properties: {}
    networks:
    - name: kafka
      type: manual
      subnets:
      - range: 10.244.0.0/30
        reserved: [10.244.0.1]
        az: lite
        cloud_properties: {}
    disk_types:
    - name: ten
      disk_size: 10_000
      cloud_properties: {}
    azs:
    - name: lite
      cloud_properties: {}
    compilation:
      workers: 2
      reuse_compilation_vms: true
      network: kafka
      az: lite
      cloud_properties: {}
    ```

1. Update the BOSH Lite cloud config using the deployment manifest created in the previous step:
  <pre class="terminal">
    $ bosh update cloud-config cloud\_config.yml
  </pre>

1. Obtain the URL and UUID BOSH Lite director information:
  <pre class="terminal">
    $ bosh status
  </pre>
  This command produces output similar to the following:
  <pre class="terminal">
    â†’ bosh status
    Config
                 /Users/pivotal/.bosh_config

    Director
      Name       Bosh Lite Director
      URL        https://192.168.50.4:25555
      Version    1.3215.0 (00000000)
      User       admin
      UUID       17a45148-1d00-43bc-af28-9882e5a6535a
      CPI        warden\_cpi
      dns        disabled
      compiled\_package\_cache enabled (provider: local)
      snapshots  disabled
  </pre>
  Record the URL and UUID from your output. These are added to the `deployment_manifest.yml` in the next step.

1. Create a BOSH Lite deployment manifest in a file called `deployment_manifest.yml` using the following as a base.
<p class="note">Replace `BOSH_LITE_UUID` and `BOSH_LITE_IP` with the value obtained in the previous step. Also replace `<CF_DOMAIN>` with your pcf dev domain.</p>

    ```yaml
    name: kafka-on-demand-broker

    director_uuid: <BOSH_LITE_UUID>

    releases:
      - name: &broker-release on-demand-service-broker
        version: latest
      - name: &service-adapter-release kafka-example-service-adapter
        version: latest
      - name: &service-release kafka-example-service
        version: latest

    stemcells:
      - alias: trusty
        os: ubuntu-trusty
        version: latest

    instance_groups:
      - name: broker
        instances: 1
        vm_type: container
        persistent_disk_type: ten
        stemcell: trusty
        azs: [lite]
        networks:
          - name: kafka
          jobs:
            - name: broker
              release: *broker-release
              properties:
                port: 8080
                username: broker #or replace with your own
                password: password #or replace with your own
                disable_ssl_cert_verification: true
                bosh:
                  url: <BOSH_LITE_IP>
                  authentication:
                    basic:
                      username: admin
                      password: admin
                cf:
                  url: https://api.<CF_DOMAIN>
                  authentication:
                    url: https://uaa.<CF_DOMAIN>
                    user_credentials:
                      username: admin
                      password: admin
                service_adapter:
                  path: /var/vcap/packages/odb-service-adapter/bin/service-adapter
              service_deployment:
                releases:
                  - name: *service-release
                    version: latest
                    jobs: [kafka_server, zookeeper_server]
                stemcell:
                  os: ubuntu-trusty
                  version: latest
              service_catalog:
                id: D94A086D-203D-4966-A6F1-60A9E2300F72
                service_name: kafka-service-with-odb
                service_description: Kafka Service
                bindable: true
                plan_updatable: true
                tags: [kafka]
                plans:
                  - name: small
                    plan_id: 11789210-D743-4C65-9D38-C80B29F4D9C8
                    description: A Kafka deployment with a single instance of each job and persistent disk
                    instance_groups:
                      - name: kafka_server
                        vm_type: container
                        instances: 1
                        persistent_disk_type: ten
                        azs: [lite]
                        networks: [kafka]
                      - name: zookeeper_server
                        vm_type: container
                        instances: 1
                        persistent_disk_type: ten
                        azs: [lite]
                        networks: [kafka]
                    properties:
                      auto_create_topics: true
                      default_replication_factor: 1
          - name: kafka-service-adapter
            release: *service-adapter-release
          - name: admin_tools
            release: *service-release

    update:
      canaries: 1
      canary_watch_time: 30000-180000
      update_watch_time: 30000-180000
      max_in_flight: 4
    ```

1. Change the BOSH deployment to use the deployment manifest created in the previous step:
    <pre class="terminal">
    $ bosh deployment deployment\_manifest.yml
    </pre>

1. Deploy the manifest:
    <pre class="terminal">
    $ bosh deploy
    </pre>

1. Obtain the IP address of the deployed broker:
    <pre class="terminal">
    $ bosh instances
    </pre>

    This command produces output similar to the following:

    <pre class="terminal">
    Acting as client 'admin' on deployment 'kafka-on-demand-broker' on 'Bosh Lite Director'

    Director task 147

    Task 147 done

    +--------------------------------------------------+---------+-----+-----------+------------+
    | Instance                                         | State   | AZ  | VM Type   | IPs        |
    +--------------------------------------------------+---------+-----+-----------+------------+
    | broker/0 (59231277-d7b8-46bb-8bbb-8154b6bae347)* | running | n/a | container | 10.244.0.2 |
    +--------------------------------------------------+---------+-----+-----------+------------+

    (*) Bootstrap node

    Instances total: 1
    </pre>

    Record the address of the broker. This address is used in the next step to create a service broker.

## <a id="create_service"></a> Step 6: Create a Service Broker on PCF Dev

1. Create a service broker on PCF Dev and enable access to its service offering. You will need the broker's credentials set in the deployment manifest and the IP of the broker VM.
<p class="note">Replace `BROKER_IP` with the value obtained in the previous step.</p>
    <pre class="terminal">
    $ cf create-service-broker kafka-broker broker password http://\<BROKER\_IP\>:8080
    </pre>

    For more details on service brokers see [here](http://docs.cloudfoundry.org/services/api.html).

1. Enable access to the broker's service plans:
    <pre class="terminal">
    $ cf enable-service-access kafka-service-with-odb
    </pre>

1. View the services offered by the broker in the marketplace:
    <pre class="terminal">
    $ cf marketplace
    </pre>

    This command produces output similar to the following:

    <pre class="terminal">
    Getting services from marketplace in org pcfdev-org / space pcfdev-space as admin...
    OK

    service                  plans        description
    kafka-service-with-odb   small        Kafka Service
    p-mysql                  512mb, 1gb   MySQL databases on demand
    p-rabbitmq               standard     RabbitMQ is a robust and scalable high-performance multi-protocol messaging broker.
    p-redis                  shared-vm    Redis service to provide a key-value store
    </pre>

1. Create a service instance using the Kafka on-demand broker.

    <pre class="terminal">
    $ cf create-service kafka-service-with-odb small k1
    </pre>

## <a id="status"></a> Step 7: Verify Your BOSH Deployment and On-Demand Service

1. Check the status of your service:
    <pre class="terminal">
    $ cf service k1
    </pre>
    Initially, the service status state is: `create in progress`. After the service is created, the status changes to: `create succeeded`.

1. Verify that the on-demand service is provisioned in the BOSH deployment
    <pre class="terminal">
    $ bosh deployments
    </pre>

    The output of this command appears as follows:

    <pre class="terminal">
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    | Name                                                  | Release(s)                            | Stemcell(s)                                      | Cloud Config |
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    | kafka-on-demand-broker                                | kafka-example-service-adapter/0+dev.2 | bosh-warden-boshlite-ubuntu-trusty-go\_agent/<%= vars.odb_warden_stemcell_version %> | latest       |
    |                                                       | on-demand-service-broker/0.2.0+dev.1  |                                                  |              |
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    | service-instance\_2715262c-8564-4cd9-b629-0ae99e6aa4b9 | kafka-example-service/0+dev.2         | bosh-warden-boshlite-ubuntu-trusty-go\_agent/<%= vars.odb_warden_stemcell_version %> | latest       |
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    </pre>

    This example shows that the service instance is provisioned and the service releases are specified in the ODB deployment manifest.


## <a id="use"></a> Step 8: Use Your On-Demand Service

The [Kafka Example App](https://github.com/pivotal-cf-experimental/kafka-example-app) shows how you can use the service instance that you created with `cf create-service`.

1. Clone the [Kafka example app](https://github.com/pivotal-cf-experimental/kafka-example-app) in your workspace:
   <pre class="terminal">
    $ git clone https<span>:</span>//github.com/pivotal-cf-experimental/kafka-example-app.git
   </pre>

1. Push the app.
   <pre class="terminal">
    $ cd kafka-example-app
      ...
    $ cf push --no-start
    </pre>

1. Bind the app to your service instance:
    <pre class="terminal">
    $ cf bind-service kafka-example-app k1
    </pre>
    <p class="note"><strong>Note</strong>: You can use <code>cf bs</code> as an alias for <code>cf bind-service</code></p>

1. Start the app:
    <pre class="terminal">
    $ cf start kafka-example-app
    </pre>

Now the app runs at `https:/kafka-example-app.local.pcfdev.io`, and you can use it to read and write to your on-demand Kafka service instance. For example:

* To write data, run `curl -XPOST http://kafka-example-app.local.pcfdev.io/queues/my-queue -d SOME-DATA`
* To read data, run `curl http://kafka-example-app.local.pcfdev.io/queues/my-queue`
